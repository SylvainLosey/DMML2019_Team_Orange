{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Orange: IMDB reviews sentiment analysis\n",
    "\n",
    "The purpose of the project is to build a model that would be able to classify the sentiment of a review of a movie and label if it has a positive or a negative sentiment. This way the opinions could be classified to be either negative or positive, while the medium sentiment is excluded from the analysis. \n",
    "Thus, the goal is to assign and weight either a positive or a negative connotation associated with each word or group of words. In addition, no weight is intended to be assigned to the words that are commonly used is sentence formation and that do not reflect any emotion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install all required dependencies for the future analysis in the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.22)\n",
      "Requirement already up-to-date: spacy in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already up-to-date: pandas in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.25.3)\n",
      "Requirement already up-to-date: seaborn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already up-to-date: sklearn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from seaborn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "[+] Download and installation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U scikit-learn spacy pandas seaborn sklearn\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import spacy\n",
    "import nltk.corpus\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/imdb_dataset.csv\") \n",
    "\n",
    "# Keep the first 100 elements to reduce the load on cpu\n",
    "data=data[:50]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base rate is 0.54\n"
     ]
    }
   ],
   "source": [
    "# Base rate, delete later\n",
    "a=data[data[\"sentiment\"]==\"positive\"].shape\n",
    "b=data[data[\"sentiment\"]==\"negative\"].shape\n",
    "base_rate=max(a[0], b[0])/data.shape[0]\n",
    "print(\"The base rate is \"+ str(base_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "#### Text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_lower(this_review):\n",
    "    this_review=this_review.lower()\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTML elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_HTML = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def remove_html(review):\n",
    "    return REMOVE_HTML.sub(\" \", review) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and remove entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_entities(this_review):\n",
    "    doc=sp(this_review)\n",
    "    \n",
    "    for i in doc.ents:\n",
    "            i=str(i)\n",
    "            this_review=this_review.replace(\" \"+i,\"\")\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing lemmatization\n",
    "def lemmatize_it(this_review):\n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    lem = sp(this_review)\n",
    "    \n",
    "   # finding lemma for each word\n",
    "    for word in lem:\n",
    "        filtered_sent.append(word.lemma_)\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "nlp = spacy.lang.en.English()\n",
    "\n",
    "def tokenize_review(this_review):\n",
    "    my_doc = nlp(this_review)\n",
    "    \n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapt spacy stopwords list to our topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print stopword list from spacy\n",
    "spacy_stopwords = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "\n",
    "remove_from_stopwordlist=[\"n't\", \"most\", \"much\", \"never\", \"no\", \"not\", \"nothing\", \"n‘t\", \"n’t\", \"really\", \"top\", \"very\", \"well\"]\n",
    "for word in spacy_stopwords:\n",
    "    if word in remove_from_stopwordlist:\n",
    "         spacy_stopwords.remove(word)\n",
    "\n",
    "add_to_stopwords=['.', ',', '!', '?', ':', '&', '...', '(', ')','-', '/', '\"', ';', '-PRON-', ' ', \"'\", '....', '  ', '*']\n",
    "for word in add_to_stopwords:\n",
    "    spacy_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Remove stopwords and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_stopwords(this_review):\n",
    "    \n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    doc = this_review\n",
    "    \n",
    "    # filtering stop words\n",
    "    for word in doc:\n",
    "        if word not in spacy_stopwords:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if tokens are words and remove those that aren't (using NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_non_words(this_review):\n",
    "    clean_sent=[]\n",
    "    for word in this_review:\n",
    "        if word in words.words():\n",
    "            clean_sent.append(word)\n",
    "    return clean_sent        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reconcatenate list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconcatenate_list_to_string (this_review):\n",
    "    this_review=' '.join(this_review)\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(this_review):\n",
    "    this_review=to_lower(this_review)\n",
    "    this_review=remove_entities(this_review)\n",
    "    this_review=recognize_it(this_review)\n",
    "    this_review=lemmatize_it(this_review)\n",
    "    this_review=eliminate_stopwords(this_review)\n",
    "    this_review=remove_non_words(this_review)\n",
    "    this_review=reconcatenate_list_to_string (this_review)\n",
    "    \n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>mastacleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>reviewer mention watch episode hook right exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production technique very ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>think wonderful way spend time hot sit air con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter love time money visually stunning film ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                mastacleaned_reviews  \n",
       "0  reviewer mention watch episode hook right exac...  \n",
       "1  wonderful little production technique very ver...  \n",
       "2  think wonderful way spend time hot sit air con...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter love time money visually stunning film ...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mastacleaned_reviews'] = data['review'].map(cleaning)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process all reviews and save to csv\n",
    "#data = pd.read_csv(\"../data/imdb_dataset.csv\") \n",
    "\n",
    "data['review'] = data['review'].map(MASTA_CLEAN)\n",
    "\n",
    "data.to_csv(\"../data/very_clean_dataset.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
