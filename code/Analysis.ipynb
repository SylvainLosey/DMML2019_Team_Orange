{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Orange: IMDB reviews sentiment analysis\n",
    "\n",
    "The purpose of the project is to build a model that would be able to classify the sentiment of a review of a movie and label if it has a positive or a negative sentiment. This way the opinions could be classified to be either negative or positive, while the medium sentiment is excluded from the analysis. \n",
    "Thus, the goal is to assign and weight either a positive or a negative connotation associated with each word or group of words. In addition, no weight is intended to be assigned to the words that are commonly used is sentence formation and that do not reflect any emotion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install all required dependencies for the future analysis in the current Jupyter kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.22)\n",
      "Requirement already up-to-date: spacy in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already up-to-date: pandas in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.25.3)\n",
      "Requirement already up-to-date: seaborn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already up-to-date: sklearn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from seaborn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.3->seaborn) (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U scikit-learn spacy pandas seaborn sklearn\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import spacy\n",
    "import nltk.corpus\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>mastacleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewer mention watch oz episode hook right e...</td>\n",
       "      <td>positive</td>\n",
       "      <td>reviewer mention watch episode hook right exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production technique very ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot sit air con...</td>\n",
       "      <td>positive</td>\n",
       "      <td>think wonderful way spend time hot sit air con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter love time money visually stunning film ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter love time money visually stunning film ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  reviewer mention watch oz episode hook right e...  positive   \n",
       "1  wonderful little production filming technique ...  positive   \n",
       "2  think wonderful way spend time hot sit air con...  positive   \n",
       "3  basically family little boy jake think zombie ...  negative   \n",
       "4  petter love time money visually stunning film ...  positive   \n",
       "\n",
       "                                mastacleaned_reviews  \n",
       "0  reviewer mention watch episode hook right exac...  \n",
       "1  wonderful little production technique very ver...  \n",
       "2  think wonderful way spend time hot sit air con...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter love time money visually stunning film ...  "
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/very_clean_dataset.csv\") \n",
    "\n",
    "# Keep the first 100 elements to reduce the load on cpu\n",
    "data=data[:50]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base rate is 0.54\n"
     ]
    }
   ],
   "source": [
    "# Base rate, delete later\n",
    "a=data[data[\"sentiment\"]==\"positive\"].shape\n",
    "b=data[data[\"sentiment\"]==\"negative\"].shape\n",
    "base_rate=max(a[0], b[0])/data.shape[0]\n",
    "print(\"The base rate is \"+ str(base_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis\n",
    "\n",
    "#### Splitting the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['mastacleaned_reviews'] # the features we want to analyze, we can play with others too\n",
    "y = data['sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize_review at 0x000001F9AA572C80>,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "count_vector = CountVectorizer(tokenizer = tokenize_review, ngram_range = (1,2))\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', count_vector), ('classifier', classifier)])\n",
    "\n",
    "# Fit Model\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strongest Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'able stand',\n",
       " 'absolutely',\n",
       " 'absolutely brilliantly',\n",
       " 'absorb',\n",
       " 'absorb audience',\n",
       " 'abstract',\n",
       " 'abstract absurd',\n",
       " 'absurd',\n",
       " 'absurd dance',\n",
       " 'absurd nature',\n",
       " 'accent',\n",
       " 'accent effective',\n",
       " 'accept',\n",
       " 'accept consequence',\n",
       " 'accept look',\n",
       " 'accomplish',\n",
       " 'accomplish nothing',\n",
       " 'accomplish think',\n",
       " 'account',\n",
       " 'account tell',\n",
       " 'account true',\n",
       " 'accurate',\n",
       " 'accurate fact',\n",
       " 'accurate meld',\n",
       " 'accurate true',\n",
       " 'accustomed',\n",
       " 'accustomed high',\n",
       " 'achieve',\n",
       " 'achieve desire',\n",
       " 'achieve human',\n",
       " 'achingly',\n",
       " 'achingly tedious',\n",
       " 'act',\n",
       " 'act horse',\n",
       " 'act movie',\n",
       " 'act skill',\n",
       " 'act willing',\n",
       " 'acting',\n",
       " 'acting b',\n",
       " 'acting expectation',\n",
       " 'acting film',\n",
       " 'acting hard',\n",
       " 'acting negatively',\n",
       " 'acting talent',\n",
       " 'acting think',\n",
       " 'acting top',\n",
       " 'action',\n",
       " 'action crime',\n",
       " 'action like',\n",
       " 'action sequence',\n",
       " 'actor',\n",
       " 'actor brit',\n",
       " 'actor certainly',\n",
       " 'actor extremely',\n",
       " 'actor film',\n",
       " 'actor good',\n",
       " 'actor mix',\n",
       " 'actor not',\n",
       " 'actor paper',\n",
       " 'actor story',\n",
       " 'actor talk',\n",
       " 'actor think',\n",
       " 'actress',\n",
       " 'actress allow',\n",
       " 'actress not',\n",
       " 'actress play',\n",
       " 'actual',\n",
       " 'actual very',\n",
       " 'actually',\n",
       " 'actually believe',\n",
       " 'actually enter',\n",
       " 'actually funny',\n",
       " 'actually hear',\n",
       " 'actually no',\n",
       " 'actually pretty',\n",
       " 'actually problem',\n",
       " 'actually product',\n",
       " 'actually very',\n",
       " 'add',\n",
       " 'add insult',\n",
       " 'addiction',\n",
       " 'addiction think',\n",
       " 'addition',\n",
       " 'addition compare',\n",
       " 'adult',\n",
       " 'adult movie',\n",
       " 'affect',\n",
       " 'affect change',\n",
       " 'affect no',\n",
       " 'affection',\n",
       " 'affection sure',\n",
       " 'age',\n",
       " 'age story',\n",
       " 'aged',\n",
       " 'aged man',\n",
       " 'agenda',\n",
       " 'agenda carver',\n",
       " 'agenda city',\n",
       " 'agent']"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 1.0\n",
      "Test set accuracy is: 0.5\n",
      "Train set precision: 1.0\n",
      "Train set recall: 1.0\n",
      "Test set precision: 1.0\n",
      "Test set recall: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "predicted_train = pipe.predict(X_train)\n",
    "predicted_test = pipe.predict(X_test)\n",
    "\n",
    "# train accuracy\n",
    "print(\"Train set accuracy: \" + str(pipe.score(X_train, y_train)))\n",
    "# test accuracy\n",
    "print(\"Test set accuracy is: \" + str(pipe.score(X_test, y_test)))\n",
    "print(\"Train set precision: \" + str(metrics.precision_score(y_train, predicted_train, pos_label=\"positive\")))\n",
    "print(\"Train set recall: \" +  str(metrics.recall_score(y_train, predicted_train, pos_label=\"positive\")))\n",
    "print(\"Test set precision: \" + str(metrics.precision_score(y_test, predicted_test, pos_label=\"positive\")))\n",
    "print(\"Test set recall: \" + str(metrics.recall_score(y_test, predicted_test, pos_label=\"positive\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(pipe, X_test, y_test, cmap=plt.cm.Greens, normalize=normalize)\n",
    "    disp.ax_.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Recall Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = pipe.decision_function(X_test)\n",
    "average_precision = average_precision_score(y_test, y_score, pos_label=\"positive\")\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "disp = plot_precision_recall_curve(pipe, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = count_vector.fit_transform(data['review'])\n",
    "y = data['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for d in range(1, 21):\n",
    "    test_tree = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    test_tree.fit(X_train, y_train)\n",
    "    scores.append(test_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(tree, X_test, y_test, cmap=plt.cm.Greens, normalize=normalize)\n",
    "    disp.ax_.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to have: \n",
    "* Precision & Recall for all methods \n",
    "* Precision-Recall curve \n",
    "* Cross-validation for all methods \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.3 KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 10, weights='uniform') #here we can change the K-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = count_vector.fit_transform(data['review'])\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(knn, X_test, y_test, cmap=plt.cm.Greens, normalize=normalize)\n",
    "    disp.ax_.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy_stopwords\n",
    "\n",
    "# using default tokenizer \n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words = None)\n",
    "bow = count.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis shown above we can see that the best performing method of classification of the reviews into binary class positive/negative is Logistic Regression method......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
