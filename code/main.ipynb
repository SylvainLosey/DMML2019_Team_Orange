{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Orange: IMDB reviews sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install all required dependencies in the current Jupyter kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\const\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\const\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\const\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (0.23)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (1.16.5)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\const\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\const\\anaconda3\\lib\\site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (0.6.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.36.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\const\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\const\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (7.2.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\const\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.36.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\const\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\const\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy>=2.2.2->en_core_web_sm==2.2.5) (7.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy pandas sklearn\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "data = pd.read_csv(\"../data/IMDB Dataset.csv\") \n",
    "\n",
    "# Keep the first 10 elements to reduce the load on cpu\n",
    "data=data[:10]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base rate is 0.7\n"
     ]
    }
   ],
   "source": [
    "#base rate, delete later\n",
    "a=data[data[\"sentiment\"]==\"positive\"].shape\n",
    "b=data[data[\"sentiment\"]==\"negative\"].shape\n",
    "base_rate=max(a[0], b[0])/data.shape[0]\n",
    "print(\"The base rate is \"+ str(base_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_lower(this_review):\n",
    "    this_review=this_review.lower()\n",
    "    return this_review\n",
    "    \n",
    "data['review'] = data['review'].map(to_lower)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  one of the other reviewers has mentioned that ...  \n",
       "1  a wonderful little production. the filming tec...  \n",
       "2  i thought this was a wonderful way to spend ti...  \n",
       "3  basically there's a family where a little boy ...  \n",
       "4  petter mattei's \"love in the time of money\" is...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REMOVE_HTML = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def remove_html(review):\n",
    "    return REMOVE_HTML.sub(\"\", review) \n",
    "\n",
    "data['cleaned_review'] = data['review'].map(remove_html)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and remove entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_it(this_review):\n",
    "    doc=sp(this_review)\n",
    "    \n",
    "    for i in doc.ents:\n",
    "            i=str(i)\n",
    "            this_review=this_review.replace(\" \"+i,\"\")\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>IDcleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>petter's \"love in the time of money\" is a visu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter mattei's \"love in the time of money\" is...   \n",
       "\n",
       "                                    IDcleaned_review  \n",
       "0  one of the other reviewers has mentioned that ...  \n",
       "1  a wonderful little production. the filming tec...  \n",
       "2  i thought this was a wonderful way to spend ti...  \n",
       "3  basically there's a family where a little boy ...  \n",
       "4  petter's \"love in the time of money\" is a visu...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['IDcleaned_review'] = data['cleaned_review'].map(recognize_it)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing lemmatization\n",
    "def lemmatize_it(this_review):\n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    lem = sp(this_review)\n",
    "    \n",
    "   # finding lemma for each word\n",
    "    for word in lem:\n",
    "        filtered_sent.append(word.lemma_)\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>IDcleaned_review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewer, have, mention,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>[a, wonderful, little, production, ., the, fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, think, this, be, a, wonderful, way, to, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>[basically, there, be, a, family, where, a, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>petter's \"love in the time of money\" is a visu...</td>\n",
       "      <td>[petter, 's, \", love, in, the, time, of, money...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter mattei's \"love in the time of money\" is...   \n",
       "\n",
       "                                    IDcleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter's \"love in the time of money\" is a visu...   \n",
       "\n",
       "                                   lemmatized_review  \n",
       "0  [one, of, the, other, reviewer, have, mention,...  \n",
       "1  [a, wonderful, little, production, ., the, fil...  \n",
       "2  [i, think, this, be, a, wonderful, way, to, sp...  \n",
       "3  [basically, there, be, a, family, where, a, li...  \n",
       "4  [petter, 's, \", love, in, the, time, of, money...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_review'] = data['IDcleaned_review'].map(lemmatize_it)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "nlp = English()\n",
    "\n",
    "def tokenize_review(this_review):\n",
    "    my_doc = nlp(this_review)\n",
    "    \n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['tokenized_review'] = data['cleaned_review'].map(tokenize_review)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt spacy stopwords list to our topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print stopword list from spacy\n",
    "spacy_stopwords = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "\n",
    "remove_from_stopwordlist=[\"n't\", \"most\", \"much\", \"never\", \"no\", \"not\", \"nothing\", \"n‘t\", \"n’t\", \"really\", \"top\", \"very\", \"well\"]\n",
    "for word in spacy_stopwords:\n",
    "    if word in remove_from_stopwordlist:\n",
    "         spacy_stopwords.remove(word)\n",
    "\n",
    "add_to_stopwords=['.', ',', '!', '?', ':', '&', '...', '(', ')','-', '/', '\"', ';']\n",
    "for word in add_to_stopwords:\n",
    "    spacy_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Remove stopwords and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_stopwords(this_review):\n",
    "    \n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    doc = this_review\n",
    "    \n",
    "    # filtering stop words\n",
    "    for word in doc:\n",
    "        if word not in spacy_stopwords:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>IDcleaned_review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>stopcleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewer, have, mention,...</td>\n",
       "      <td>[reviewer, mention, watch, oz, episode, -PRON-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>[a, wonderful, little, production, ., the, fil...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, think, this, be, a, wonderful, way, to, sp...</td>\n",
       "      <td>[think, wonderful, way, spend, time, hot, sit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>[basically, there, be, a, family, where, a, li...</td>\n",
       "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>petter's \"love in the time of money\" is a visu...</td>\n",
       "      <td>[petter, 's, \", love, in, the, time, of, money...</td>\n",
       "      <td>[petter, love, time, money, visually, stunning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter mattei's \"love in the time of money\" is...   \n",
       "\n",
       "                                    IDcleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter's \"love in the time of money\" is a visu...   \n",
       "\n",
       "                                   lemmatized_review  \\\n",
       "0  [one, of, the, other, reviewer, have, mention,...   \n",
       "1  [a, wonderful, little, production, ., the, fil...   \n",
       "2  [i, think, this, be, a, wonderful, way, to, sp...   \n",
       "3  [basically, there, be, a, family, where, a, li...   \n",
       "4  [petter, 's, \", love, in, the, time, of, money...   \n",
       "\n",
       "                                  stopcleaned_review  \n",
       "0  [reviewer, mention, watch, oz, episode, -PRON-...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [think, wonderful, way, spend, time, hot, sit,...  \n",
       "3  [basically, family, little, boy, jake, think, ...  \n",
       "4  [petter, love, time, money, visually, stunning...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stopcleaned_review'] = data['lemmatized_review'].map(eliminate_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we do Bag of Words?\n",
    "Do we do TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MASTA_CLEAN(this_review):\n",
    "    this_review=to_lower(this_review)\n",
    "    this_review=remove_html(this_review)\n",
    "    this_review=recognize_it(this_review)\n",
    "    this_review=lemmatize_it(this_review)\n",
    "    this_review=eliminate_stopwords(this_review)\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>IDcleaned_review</th>\n",
       "      <th>lemmatized_review</th>\n",
       "      <th>stopcleaned_review</th>\n",
       "      <th>mastacleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewer, have, mention,...</td>\n",
       "      <td>[reviewer, mention, watch, oz, episode, -PRON-...</td>\n",
       "      <td>[reviewer, mention, watch, oz, episode, -PRON-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>[a, wonderful, little, production, ., the, fil...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>[i, think, this, be, a, wonderful, way, to, sp...</td>\n",
       "      <td>[think, wonderful, way, spend, time, hot, sit,...</td>\n",
       "      <td>[think, wonderful, way, spend, time, hot, sit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>[basically, there, be, a, family, where, a, li...</td>\n",
       "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
       "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>petter's \"love in the time of money\" is a visu...</td>\n",
       "      <td>[petter, 's, \", love, in, the, time, of, money...</td>\n",
       "      <td>[petter, love, time, money, visually, stunning...</td>\n",
       "      <td>[petter, love, time, money, visually, stunning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter mattei's \"love in the time of money\" is...   \n",
       "\n",
       "                                    IDcleaned_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  a wonderful little production. the filming tec...   \n",
       "2  i thought this was a wonderful way to spend ti...   \n",
       "3  basically there's a family where a little boy ...   \n",
       "4  petter's \"love in the time of money\" is a visu...   \n",
       "\n",
       "                                   lemmatized_review  \\\n",
       "0  [one, of, the, other, reviewer, have, mention,...   \n",
       "1  [a, wonderful, little, production, ., the, fil...   \n",
       "2  [i, think, this, be, a, wonderful, way, to, sp...   \n",
       "3  [basically, there, be, a, family, where, a, li...   \n",
       "4  [petter, 's, \", love, in, the, time, of, money...   \n",
       "\n",
       "                                  stopcleaned_review  \\\n",
       "0  [reviewer, mention, watch, oz, episode, -PRON-...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [think, wonderful, way, spend, time, hot, sit,...   \n",
       "3  [basically, family, little, boy, jake, think, ...   \n",
       "4  [petter, love, time, money, visually, stunning...   \n",
       "\n",
       "                                mastacleaned_reviews  \n",
       "0  [reviewer, mention, watch, oz, episode, -PRON-...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [think, wonderful, way, spend, time, hot, sit,...  \n",
       "3  [basically, family, little, boy, jake, think, ...  \n",
       "4  [petter, love, time, money, visually, stunning...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mastacleaned_reviews'] = data['review'].map(MASTA_CLEAN)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['review'] # the features we want to analyze, we can play with others too\n",
    "y = data['sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...,\n",
       "                                 tokenizer=<function MASTA_CLEAN at 0x000001AC39D9BF78>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "classifier = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = MASTA_CLEAN)\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector), ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Accuracy: 0.75\n",
      " test Accuracy: 1.0\n",
      " Precision: [1.]\n",
      " Recall: [1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" train Accuracy:\",pipe.score(X_train, y_train))\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))\n",
    "\n",
    "#completer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ac38587348>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_reg = pipe\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "   \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"negative\", \"positive\"])\n",
    "    ax.yaxis.set_ticklabels([\"negative\", \"positive\"])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_train, log_reg.predict(X_train), classes=data.sentiment,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = spacy_stopwords\n",
    "\n",
    "# using default tokenizer \n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words = None)\n",
    "bow = count.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-4f66baab8f93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"M8[ns]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for d in range(1, 21):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to have: \n",
    "* Precision & Recall for all methods \n",
    "* Precision-Recall curve \n",
    "* Cross-validation for all methods \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform') #here we can change the K-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = data['mastacleaned_reviews']\n",
    "z = data['sentiment']\n",
    "print(W.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "W_train, W_test, z_train, z_test = train_test_split(W, z, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.fit(W_train, z_train) problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
