{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Orange: IMDB reviews sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install all required dependencies in the current Jupyter kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.23)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from sklearn) (0.21.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (0.5.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\users\\cyrill\\anaconda3\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy pandas sklearn\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, rows, column names with read_csv (see later) \n",
    "data = pd.read_csv(\"../data/IMDB Dataset.csv\") \n",
    "\n",
    "# Keep the first 10 elements to reduce the load on cpu\n",
    "data=data[:100]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base rate is 0.58\n"
     ]
    }
   ],
   "source": [
    "#base rate, delete later\n",
    "a=data[data[\"sentiment\"]==\"positive\"].shape\n",
    "b=data[data[\"sentiment\"]==\"negative\"].shape\n",
    "base_rate=max(a[0], b[0])/data.shape[0]\n",
    "print(\"The base rate is \"+ str(base_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_lower(this_review):\n",
    "    this_review=this_review.lower()\n",
    "    return this_review\n",
    "    \n",
    "#data['review'] = data['review'].map(to_lower)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_HTML = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def remove_html(review):\n",
    "    return REMOVE_HTML.sub(\" \", review) \n",
    "\n",
    "#data['cleaned_review'] = data['review'].map(remove_html)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and remove entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_it(this_review):\n",
    "    doc=sp(this_review)\n",
    "    \n",
    "    for i in doc.ents:\n",
    "            i=str(i)\n",
    "            this_review=this_review.replace(\" \"+i,\"\")\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['IDcleaned_review'] = data['cleaned_review'].map(recognize_it)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing lemmatization\n",
    "def lemmatize_it(this_review):\n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    lem = sp(this_review)\n",
    "    \n",
    "   # finding lemma for each word\n",
    "    for word in lem:\n",
    "        filtered_sent.append(word.lemma_)\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data['lemmatized_review'] = data['IDcleaned_review'].map(lemmatize_it)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "nlp = English()\n",
    "\n",
    "def tokenize_review(this_review):\n",
    "    my_doc = nlp(this_review)\n",
    "    \n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['tokenized_review'] = data['cleaned_review'].map(tokenize_review)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt spacy stopwords list to our topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print stopword list from spacy\n",
    "spacy_stopwords = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "\n",
    "remove_from_stopwordlist=[\"n't\", \"most\", \"much\", \"never\", \"no\", \"not\", \"nothing\", \"n‘t\", \"n’t\", \"really\", \"top\", \"very\", \"well\"]\n",
    "for word in spacy_stopwords:\n",
    "    if word in remove_from_stopwordlist:\n",
    "         spacy_stopwords.remove(word)\n",
    "\n",
    "add_to_stopwords=['.', ',', '!', '?', ':', '&', '...', '(', ')','-', '/', '\"', ';', '-PRON-', ' ']\n",
    "for word in add_to_stopwords:\n",
    "    spacy_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Remove stopwords and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_stopwords(this_review):\n",
    "    \n",
    "    filtered_sent=[]\n",
    "\n",
    "    #  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "    doc = this_review\n",
    "    \n",
    "    # filtering stop words\n",
    "    for word in doc:\n",
    "        if word not in spacy_stopwords:\n",
    "            filtered_sent.append(word)\n",
    "    return filtered_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['stopcleaned_review'] = data['lemmatized_review'].map(eliminate_stopwords)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we do Bag of Words?\n",
    "Do we do TF-IDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MASTA_CLEAN(this_review):\n",
    "    this_review=to_lower(this_review)\n",
    "    this_review=remove_html(this_review)\n",
    "    this_review=recognize_it(this_review)\n",
    "    this_review=lemmatize_it(this_review)\n",
    "    this_review=eliminate_stopwords(this_review)\n",
    "    return this_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>mastacleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[reviewer, mention, watch, oz, episode, hook, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[think, wonderful, way, spend, time, hot, sit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, family, little, boy, jake, think, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, love, time, money, visually, stunning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                mastacleaned_reviews  \n",
       "0  [reviewer, mention, watch, oz, episode, hook, ...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [think, wonderful, way, spend, time, hot, sit,...  \n",
       "3  [basically, family, little, boy, jake, think, ...  \n",
       "4  [petter, love, time, money, visually, stunning...  "
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mastacleaned_reviews'] = data['review'].map(MASTA_CLEAN)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['review'] # the features we want to analyze, we can play with others too\n",
    "y = data['sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function MASTA_CLEAN at 0x000002373B329488>,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "classifier = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "count_vector = CountVectorizer(tokenizer = MASTA_CLEAN, ngram_range = (1,2))\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', count_vector), ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Logistic Regression (precision and recall are calculated for positive reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 1.0\n",
      "Test set accuracy is: 0.55\n",
      "Train set precision: 1.0\n",
      "Train set recall: 1.0\n",
      "Test set precision: 1.0\n",
      "Test set recall: 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "predicted_train = pipe.predict(X_train)\n",
    "predicted_test = pipe.predict(X_test)\n",
    "# train accuracy\n",
    "print(\"Train set accuracy: \" + str(pipe.score(X_train, y_train)))\n",
    "# test accuracy\n",
    "print(\"Test set accuracy is: \" + str(pipe.score(X_test, y_test)))\n",
    "print(\"Train set precision: \" + str(metrics.precision_score(y_train, predicted_train, pos_label=\"positive\")))\n",
    "print(\"Train set recall: \" +  str(metrics.recall_score(y_train, predicted_train, pos_label=\"positive\")))\n",
    "print(\"Test set precision: \" + str(metrics.precision_score(y_test, predicted_test, pos_label=\"positive\")))\n",
    "print(\"Test set recall: \" + str(metrics.recall_score(y_test, predicted_test, pos_label=\"positive\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for test set, without normalization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23739fd8f28>"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "log_reg = pipe\n",
    "log_reg.fit(X_train,y_train)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Greens):\n",
    "   \n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix for test set, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix for test set, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "    \n",
    "    ax.xaxis.set_ticklabels([\"negative\", \"positive\"])\n",
    "    ax.yaxis.set_ticklabels([\"negative\", \"positive\"])\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout();\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, log_reg.predict(X_test), classes=data.sentiment,\n",
    "                      title='Confusion matrix for test set, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = spacy_stopwords\n",
    "\n",
    "# using default tokenizer \n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words = None)\n",
    "bow = count.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'First of all, let\\'s get a few things straight here: a) I AM an anime fan- always has been as a matter of fact (I used to watch Speed Racer all the time in Preschool). b) I DO like several B-Movies because they\\'re hilarious. c) I like the Godzilla movies- a lot.<br /><br />Moving on, when the movie first comes on, it seems like it\\'s going to be your usual B-movie, down to the crappy FX, but all a sudden- BOOM! the anime comes on! This is when the movie goes WWWAAAAAYYYYY downhill.<br /><br />The animation is VERY bad & cheap, even worse than what I remember from SPEED RACER, for crissakes! In fact, it\\'s so cheap, one of the few scenes from the movie I \"vividly\" remember is when a bunch of kids run out of a school... & it\\'s the same kids over & over again! The FX are terrible, too; the dinosaurs look worse than Godzilla. In addition, the transition to live action to animation is unorganized, the dialogue & voices(especially the English dub that I viewed) was horrid & I was begging my dad to take the tape out of the DVD/ VHS player; The only thing that kept me surviving was cracking out jokes & comments like the robots & Joel/Mike on MST3K (you pick the season). Honestly, this is the only way to barely enjoy this movie & survive it at the same time.<br /><br />Heck, I\\'m planning to show this to another fellow otaku pal of mine on Halloween for a B-Movie night. Because it\\'s stupid, pretty painful to watch & unintentionally hilarious at the same time, I\\'m giving this movie a 3/10, an improvement from the 0.5/10 I was originally going to give it.<br /><br />(According to my grading scale: 3/10 means Pretty much both boring & bad. As fun as counting to three unless you find a way to make fun of it, then it will become as fun as counting to 15.)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-455-4f66baab8f93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'M8[ns]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'First of all, let\\'s get a few things straight here: a) I AM an anime fan- always has been as a matter of fact (I used to watch Speed Racer all the time in Preschool). b) I DO like several B-Movies because they\\'re hilarious. c) I like the Godzilla movies- a lot.<br /><br />Moving on, when the movie first comes on, it seems like it\\'s going to be your usual B-movie, down to the crappy FX, but all a sudden- BOOM! the anime comes on! This is when the movie goes WWWAAAAAYYYYY downhill.<br /><br />The animation is VERY bad & cheap, even worse than what I remember from SPEED RACER, for crissakes! In fact, it\\'s so cheap, one of the few scenes from the movie I \"vividly\" remember is when a bunch of kids run out of a school... & it\\'s the same kids over & over again! The FX are terrible, too; the dinosaurs look worse than Godzilla. In addition, the transition to live action to animation is unorganized, the dialogue & voices(especially the English dub that I viewed) was horrid & I was begging my dad to take the tape out of the DVD/ VHS player; The only thing that kept me surviving was cracking out jokes & comments like the robots & Joel/Mike on MST3K (you pick the season). Honestly, this is the only way to barely enjoy this movie & survive it at the same time.<br /><br />Heck, I\\'m planning to show this to another fellow otaku pal of mine on Halloween for a B-Movie night. Because it\\'s stupid, pretty painful to watch & unintentionally hilarious at the same time, I\\'m giving this movie a 3/10, an improvement from the 0.5/10 I was originally going to give it.<br /><br />(According to my grading scale: 3/10 means Pretty much both boring & bad. As fun as counting to three unless you find a way to make fun of it, then it will become as fun as counting to 15.)'"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the depth of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for d in range(1, 21):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy', max_depth=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)\n",
    "plt.ylabel('accuracy', fontsize=15)\n",
    "plt.xlabel('depth', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to have: \n",
    "* Precision & Recall for all methods \n",
    "* Precision-Recall curve \n",
    "* Cross-validation for all methods \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors= 10, weights='uniform') #here we can change the K-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = count_vector.fit_transform(data['review'])\n",
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
